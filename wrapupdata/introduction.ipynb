{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from daam import set_seed\n",
    "from models.diffuserpipeline import StableDiffusionPipelineForNegativePrompts\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_id = 'stabilityai/stable-diffusion-2-base'\n",
    "device = 'cuda'\n",
    "pipe = StableDiffusionPipelineForNegativePrompts.from_pretrained(model_id, use_auth_token=True)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompt = \"In a lively park.\"\n",
    "negative_prompt = \"bench\"   \n",
    "seed = 985772\n",
    "\n",
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, num_inference_steps=30, generator=set_seed(seed),negative_time = [])\n",
    "image = out.images[0]\n",
    "image.save(\"intro/bench_base_985772.png\")\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "prompt = \"In a lively park.\"\n",
    "negative_prompt = \"bench\"   \n",
    "seed = 985772\n",
    "\n",
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, negative_prompt = negative_prompt,num_inference_steps=30, generator=set_seed(seed))\n",
    "image = out.images[0]\n",
    "image.save(\"intro/bench_trivial_985772.png\")\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "# 399596 bench laughter and barks across the sunlit park."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, negative_prompt = negative_prompt,num_inference_steps=30, generator=set_seed(seed),negative_time = [11,12,13])\n",
    "image = out.images[0]\n",
    "image.save(\"intro/bench_ours_985772.png\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from daam import set_seed\n",
    "from models.diffuserpipeline import StableDiffusionPipelineForNegativePrompts\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_id = 'stabilityai/stable-diffusion-2-base'\n",
    "device = 'cuda'\n",
    "pipe = StableDiffusionPipelineForNegativePrompts.from_pretrained(model_id, use_auth_token=True)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompt = \"In a lively park.\"\n",
    "negative_prompt = \"bench\"   \n",
    "seed = 985772\n",
    "\n",
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, num_inference_steps=30, generator=set_seed(seed),negative_time = [])\n",
    "image = out.images[0]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "prompt = \"In a lively park.\"\n",
    "negative_prompt = \"bench\"   \n",
    "seed = 985772\n",
    "\n",
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, negative_prompt = negative_prompt,num_inference_steps=30, generator=set_seed(seed))\n",
    "image = out.images[0]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from daam import set_seed\n",
    "from models.diffuserpipeline import StableDiffusionPipelineForNegativePrompts\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_id = 'stabilityai/stable-diffusion-2-base'\n",
    "device = 'cuda'\n",
    "pipe = StableDiffusionPipelineForNegativePrompts.from_pretrained(model_id, use_auth_token=True)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompt = \"In a lively park.\"\n",
    "negative_prompt = \"bench\"   \n",
    "seed = 255835\n",
    "\n",
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, num_inference_steps=30, generator=set_seed(seed),negative_time = [])\n",
    "image = out.images[0]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "prompt = \"In a lively park.\"\n",
    "negative_prompt = \"bench\"   \n",
    "seed = 255835\n",
    "\n",
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, negative_prompt = negative_prompt,num_inference_steps=30, generator=set_seed(seed))\n",
    "image = out.images[0]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, negative_prompt = negative_prompt,num_inference_steps=30, generator=set_seed(seed),negative_time = [10, 11,12,13])\n",
    "image = out.images[0]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# street in rainy day\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from daam import set_seed\n",
    "from models.diffuserpipeline import StableDiffusionPipelineForNegativePrompts\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_id = 'stabilityai/stable-diffusion-2-base'\n",
    "device = 'cuda'\n",
    "pipe = StableDiffusionPipelineForNegativePrompts.from_pretrained(model_id, use_auth_token=True)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompt = \"street in rainy day\"\n",
    "negative_prompt = \"car\"   \n",
    "seed = 669351\n",
    "\n",
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, num_inference_steps=30, generator=set_seed(seed),negative_time = [])\n",
    "image = out.images[0]\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "prompt = \"street in rainy day\"\n",
    "negative_prompt = \"car\"   \n",
    "seed = 669351\n",
    "\n",
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, negative_prompt = negative_prompt,num_inference_steps=30, generator=set_seed(seed))\n",
    "image = out.images[0]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, negative_prompt = negative_prompt,num_inference_steps=30, generator=set_seed(seed),negative_time = [7,8,9])\n",
    "image = out.images[0]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# street in rainy day\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from daam import set_seed\n",
    "from models.diffuserpipeline import StableDiffusionPipelineForNegativePrompts\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_id = 'stabilityai/stable-diffusion-2-base'\n",
    "device = 'cuda'\n",
    "pipe = StableDiffusionPipelineForNegativePrompts.from_pretrained(model_id, use_auth_token=True)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompt = \"street in rainy day\"\n",
    "negative_prompt = \"umbrella\"   \n",
    "seed = 122175\n",
    "\n",
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, num_inference_steps=30, generator=set_seed(seed),negative_time = [])\n",
    "image = out.images[0]\n",
    "image.save(\"intro/umbrella_base_122175.png\")\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "prompt = \"street in rainy day\"\n",
    "negative_prompt = \"umbrella\"\n",
    "seed = 122175\n",
    "\n",
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, negative_prompt = negative_prompt,num_inference_steps=30, generator=set_seed(seed))\n",
    "image = out.images[0]\n",
    "image.save(\"intro/umbrella_trivial_122175.png\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"street in rainy day\"\n",
    "negative_prompt = \"umbrella\"\n",
    "seed = 122175\n",
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, negative_prompt = negative_prompt,num_inference_steps=30, generator=set_seed(seed),negative_time = [9,10,11])\n",
    "image = out.images[0]\n",
    "image.save(\"intro/umbrella_ours_122175.png\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# street in rainy day\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from daam import set_seed\n",
    "from models.diffuserpipeline import StableDiffusionPipelineForNegativePrompts\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_id = 'stabilityai/stable-diffusion-2-base'\n",
    "device = 'cuda'\n",
    "pipe = StableDiffusionPipelineForNegativePrompts.from_pretrained(model_id, use_auth_token=True)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompt = \"a sharp pop resonates through the crisp air.\"\n",
    "negative_prompt = \"traffic light\"   \n",
    "seed = 135122\n",
    "\n",
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, num_inference_steps=30, generator=set_seed(seed),negative_time = [])\n",
    "image = out.images[0]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "prompt = \"a sharp pop resonates through the crisp air.\"\n",
    "negative_prompt = \"traffic light\"   \n",
    "seed = 135122\n",
    "\n",
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, negative_prompt = negative_prompt,num_inference_steps=30, generator=set_seed(seed))\n",
    "image = out.images[0]\n",
    "image.save(\"intro/umbrella_ours_122175.png\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, negative_prompt = negative_prompt,num_inference_steps=30, generator=set_seed(seed),negative_time = [6, 7,8,9,10])\n",
    "image = out.images[0]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# street in rainy day\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from daam import set_seed\n",
    "from models.diffuserpipeline import StableDiffusionPipelineForNegativePrompts\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model_id = 'stabilityai/stable-diffusion-2-base'\n",
    "device = 'cuda'\n",
    "pipe = StableDiffusionPipelineForNegativePrompts.from_pretrained(model_id, use_auth_token=True)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompt = \"softly slices through the evening's culinary creation.\"\n",
    "negative_prompt = \"knife\"   \n",
    "seed = 313689\n",
    "\n",
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, num_inference_steps=30, generator=set_seed(seed),negative_time = [])\n",
    "image = out.images[0]\n",
    "image.save(\"intro/knife_base_313689.png\")\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "prompt = \"softly slices through the evening's culinary creation.\"\n",
    "negative_prompt = \"knife\"   \n",
    "seed = 313689\n",
    "\n",
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, negative_prompt = negative_prompt,num_inference_steps=30, generator=set_seed(seed))\n",
    "image = out.images[0]\n",
    "image.save(\"intro/knife_trivial_313689.png\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast(dtype=torch.float16), torch.no_grad():\n",
    "    out = pipe(prompt, negative_prompt = negative_prompt,num_inference_steps=30, generator=set_seed(seed),negative_time = [7])\n",
    "image = out.images[0]\n",
    "image.save(\"intro/knife_ours_313689.png\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "778950 oven 49"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
